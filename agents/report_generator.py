"""
Executive Report Generator â€” produces a comprehensive Markdown report.

Includes: business summary, architecture overview, maturity score,
risk heatmap, prioritised recommendations, and evidence citations.
"""

from __future__ import annotations

import json
import logging
from typing import Any, Dict, List

logger = logging.getLogger(__name__)


def _format_list(items: List[str], bullet: str = "â€¢") -> str:
    """Format a list of strings as bullet points."""
    if not items:
        return "_None detected._"
    return "\n".join(f"  {bullet} {item}" for item in items)


def _severity_emoji(score: int) -> str:
    """Return an emoji indicator based on maturity score."""
    if score >= 80:
        return "ğŸŸ¢"
    if score >= 60:
        return "ğŸŸ¡"
    if score >= 40:
        return "ğŸŸ "
    return "ğŸ”´"


def _risk_heatmap(gap_analysis: Dict[str, Any]) -> str:
    """Generate a textual risk heatmap."""
    risks = gap_analysis.get("risks", [])
    security = gap_analysis.get("security_issues", [])
    gaps = gap_analysis.get("gaps", [])

    lines: List[str] = []

    if security:
        lines.append("### ğŸ”´ Critical â€” Security")
        for issue in security:
            lines.append(f"  âš ï¸  {issue}")

    if risks:
        lines.append("\n### ğŸŸ  High â€” Technical Risks")
        for risk in risks:
            lines.append(f"  âš ï¸  {risk}")

    if gaps:
        lines.append("\n### ğŸŸ¡ Medium â€” Practice Gaps")
        for gap in gaps:
            lines.append(f"  ğŸ“‹ {gap}")

    if not lines:
        lines.append("  âœ… No significant risks detected.")

    return "\n".join(lines)


def report_generator_agent(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    Generate the full executive report from pipeline state.

    This is a pure formatting function with no LLM calls â€” it assembles
    all prior analysis results into a clean Markdown document.

    Args:
        state: Final pipeline state with all analysis results.

    Returns:
        Dict with 'final_report' key containing Markdown string.
    """
    # â”€â”€ Extract data from state â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    business_ctx = state.get("business_context", {})
    architecture = state.get("architecture", {})
    metrics = state.get("complexity_metrics", {})
    entities = state.get("entities", {})
    workflows = state.get("workflows", {})
    gap_analysis = state.get("gap_analysis", {})
    evidence = state.get("evidence", [])
    dependencies = state.get("dependencies", {})

    maturity = gap_analysis.get("maturity_score", 0)
    emoji = _severity_emoji(maturity)

    # â”€â”€ Build report sections â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    sections: List[str] = []

    # Header
    sections.append("# ğŸ§  Repository Intelligence Report\n")
    sections.append(f"**Maturity Score: {emoji} {maturity}/100**\n")

    # Business summary
    sections.append("---\n## ğŸ’¼ Business Context\n")
    domain = business_ctx.get("domain", state.get("business_summary", "Not analysed."))
    sections.append(f"**Domain:** {domain}\n")

    users = business_ctx.get("primary_users", [])
    if users:
        sections.append(f"**Target Users:** {', '.join(users)}\n")

    features = business_ctx.get("core_features", [])
    if features:
        sections.append("**Core Features:**")
        sections.append(_format_list(features))

    biz_workflows = business_ctx.get("business_workflows", [])
    if biz_workflows:
        sections.append("\n**Business Workflows:**")
        sections.append(_format_list(biz_workflows))

    confidence = business_ctx.get("confidence_score", 0)
    if confidence:
        sections.append(f"\n_Analysis confidence: {confidence:.0%}_")

    # Tech stack
    sections.append("\n---\n## ğŸ”§ Tech Stack\n")
    sections.append(state.get("tech_stack", "Not detected."))

    # Languages breakdown
    languages = metrics.get("languages", {})
    if languages:
        sections.append("\n**Language Distribution (LOC):**")
        for lang, loc in sorted(languages.items(), key=lambda x: -x[1]):
            sections.append(f"  â€¢ {lang}: {loc:,} lines")

    # Architecture
    sections.append("\n---\n## ğŸ—ï¸ Architecture Overview\n")
    arch_pattern = architecture.get("pattern", "unknown")
    sections.append(f"**Pattern:** {arch_pattern}")
    sections.append(f"**API Style:** {architecture.get('api_style', 'unknown')}")
    sections.append(f"**Auth:** {architecture.get('auth_mechanism', 'unknown')}")
    sections.append(f"**Database:** {architecture.get('database_type', 'unknown')}")

    layers = architecture.get("layers", [])
    if layers:
        sections.append(f"\n**Layers:** {' â†’ '.join(layers)}")

    # Complexity metrics
    sections.append("\n---\n## ğŸ“Š Complexity Metrics\n")
    sections.append(f"| Metric | Value |")
    sections.append(f"|--------|-------|")
    sections.append(f"| Total Files | {metrics.get('total_files', 'N/A')} |")
    sections.append(f"| Lines of Code | {metrics.get('total_loc', 'N/A'):,} |")
    sections.append(f"| Service Count | {metrics.get('service_count', 'N/A')} |")
    sections.append(f"| Test Coverage | {metrics.get('test_coverage_heuristic', 'N/A')} |")

    # Domain entities
    sections.append("\n---\n## ğŸ·ï¸ Domain Entities\n")
    domain_entities = entities.get("domain_entities", [])
    api_endpoints = entities.get("api_endpoints", [])
    db_models = entities.get("database_models", [])
    integrations = entities.get("external_integrations", [])

    if domain_entities:
        sections.append("**Models:** " + ", ".join(domain_entities))
    if api_endpoints:
        sections.append("\n**API Endpoints:**")
        sections.append(_format_list(api_endpoints))
    if db_models:
        sections.append("\n**Database Models:** " + ", ".join(db_models))
    if integrations:
        sections.append("\n**External Integrations:** " + ", ".join(integrations))

    # Workflows
    sections.append("\n---\n## ğŸ”€ Application Workflows\n")
    flows = workflows.get("primary_flows", [])
    req_paths = workflows.get("request_paths", [])
    bg_jobs = workflows.get("background_jobs", [])

    if flows:
        sections.append("**User Flows:**")
        sections.append(_format_list(flows))
    if req_paths:
        sections.append("\n**Request Paths:**")
        sections.append(_format_list(req_paths))
    if bg_jobs:
        sections.append("\n**Background Jobs:**")
        sections.append(_format_list(bg_jobs))

    # Dependencies
    circular = dependencies.get("circular_dependencies", [])
    coupling = dependencies.get("high_coupling_modules", [])
    if circular or coupling:
        sections.append("\n---\n## ğŸ”— Dependency Analysis\n")
        if circular:
            sections.append("**âš ï¸ Circular Dependencies:**")
            for cycle in circular[:5]:
                sections.append(f"  ğŸ”„ {' â†’ '.join(cycle)}")
        if coupling:
            sections.append("\n**High-Coupling Modules:**")
            sections.append(_format_list(coupling))

    # Risk heatmap
    sections.append("\n---\n## ğŸ”¥ Risk Heatmap\n")
    sections.append(_risk_heatmap(gap_analysis))

    # Strengths
    strengths = gap_analysis.get("strengths", [])
    if strengths:
        sections.append("\n---\n## âœ… Strengths\n")
        sections.append(_format_list(strengths, "âœ“"))

    # Recommendations
    recommendations = gap_analysis.get("recommendations", [])
    if recommendations:
        sections.append("\n---\n## ğŸ“Œ Prioritised Recommendations\n")
        for i, rec in enumerate(recommendations, 1):
            sections.append(f"  **{i}.** {rec}")

    # Evidence
    if evidence:
        sections.append("\n---\n## ğŸ“‚ Evidence Files\n")
        for path in evidence[:20]:
            sections.append(f"  ğŸ“„ `{path}`")

    # Footer
    sections.append("\n---\n_Generated by Repository Intelligence System v2.0_")

    report = "\n".join(sections)

    logger.info("Executive report generated: %d characters", len(report))
    return {"final_report": report}
